# 뉴스 이미지 수집 개선 계획

## 현재 상황 요약

### ✅ 해결된 문제
- **중복 기사 제거**: 하이브리드 방식(제목 40% + 내용 70% + 키워드 50%) 적용 완료
- **일부 사이트 이미지 수집 성공**: Newsis, 한국일보에서 차트/이미지 정상 수집

### ❌ 남은 문제
- **연합뉴스, 뉴스1**: 이미지 0개 (고급 Lazy Loading 추정)
- **원인 불명**: 스크롤/필터/AI 중 어디서 실패하는지 불분명

---

## 디버깅 전략 (3단계)

### Phase 1: 진단 로깅 추가 ⭐ **최우선**

**목적:** 이미지 수집 파이프라인의 각 단계별 상태 확인

#### 추가할 로그 위치

**1. 이미지 발견 직후 (Line ~343 이후)**
```python
logger.info(f"[DEBUG] {item['url']} - 원본 이미지 발견: {len(images_found)}개")
for idx, img in enumerate(images_found[:10]):
    logger.info(f"  [{idx+1}] {img['url'][:100]}... (w:{img['width']}, h:{img['height']})")
```

**2. 중복 제거 후 (Line ~363 이후)**
```python
logger.info(f"[DEBUG] 중복 제거 후: {len(candidates)}개")
```

**3. 필터링 상세 (Line ~325 근처에 추가)**
```python
# 필터에 걸린 이유 기록
if any(x in src_lower for x in trash_keywords):
    logger.debug(f"[FILTER] 키워드 차단: {src[:80]}")
    continue
    
if w > 0 and w < 150 and h > 0 and h < 150:
    logger.debug(f"[FILTER] 크기 차단: {src[:80]} ({w}x{h})")
    continue
```

**4. AI 분석 결과 (Line ~374 근처)**
```python
if not analysis.get("relevant"):
    logger.debug(f"[AI] 거부됨: {img['url'][:80]} - {analysis}")
```

#### 기대 효과
- 연합뉴스/뉴스1에서 **이미지를 아예 못 찾는지** 확인
- 찾았다면 **어느 단계에서 걸러지는지** 파악
- 정확한 원인 특정 가능

---

### Phase 2: 로딩 전략 개선

**진단 로그 결과에 따라 선택적 적용**

#### Option A: networkidle 적용 (이미지 발견 0개인 경우)

**현재 (Line 285):**
```python
page.goto(item["url"], timeout=CRAWL_TIMEOUT*1000, wait_until="domcontentloaded")
```

**개선안:**
```python
try:
    # networkidle: 네트워크 활동이 500ms 동안 없을 때까지 대기
    page.goto(item["url"], timeout=20000, wait_until="networkidle")
except:
    # 타임아웃 시 domcontentloaded로 폴백
    page.goto(item["url"], timeout=CRAWL_TIMEOUT*1000, wait_until="domcontentloaded")
```

**장점:** JavaScript 완전 실행 보장  
**단점:** 광고 때문에 느려질 수 있음 (타임아웃 필수)

---

#### Option B: 스크롤 방식 개선 (이미지 발견 0개인 경우)

**현재 (Line 287-290):**
```python
for _ in range(5):
    page.evaluate("window.scrollBy(0, document.body.scrollHeight / 5)")
    page.wait_for_timeout(2000)
```

**개선안 1: documentElement 사용**
```python
for i in range(5):
    # body 대신 documentElement (더 범용적)
    page.evaluate(f"window.scrollTo(0, document.documentElement.scrollHeight * {(i+1)/5})")
    page.wait_for_timeout(1500)
```

**개선안 2: 스크롤 이벤트 강제 발생**
```python
for i in range(5):
    page.evaluate("""
        window.scrollTo(0, document.documentElement.scrollHeight * %f);
        window.dispatchEvent(new Event('scroll'));
    """ % ((i+1)/5))
    page.wait_for_timeout(1500)
```

**장점:** Lazy Loading 트리거 확률 증가  
**단점:** 여전히 고급 Intersection Observer는 못 잡을 수 있음

---

#### Option C: 하이브리드 (추천)

```python
# 1. networkidle로 초기 로딩
try:
    page.goto(item["url"], timeout=15000, wait_until="networkidle")
except:
    page.goto(item["url"], timeout=CRAWL_TIMEOUT*1000, wait_until="domcontentloaded")

# 2. 빠른 스크롤 3회
for i in range(3):
    page.evaluate(f"""
        window.scrollTo(0, document.documentElement.scrollHeight * {(i+1)/3});
        window.dispatchEvent(new Event('scroll'));
    """)
    page.wait_for_timeout(1000)
```

**장점:** 속도와 안정성 균형  
**소요 시간:** 약 18초 (15초 로딩 + 3초 스크롤)

---

### Phase 3: 필터 완화 테스트

**진단 로그에서 "필터에 많이 걸림" 확인 시 적용**

#### 임시 필터 완화 (Line 321-336)

**현재:**
```python
trash_keywords = [
    '.svg', '.gif', 'logo', 'icon', 'banner', 'ad', 'button', 'btn',
    'reporter', 'profile', 'journalist', 'avatar'
]

if w > 0 and w < 150 and h > 0 and h < 150:
    continue
```

**테스트용 완화:**
```python
# 확실한 것만 차단
trash_keywords = ['.svg', '.gif']

# 크기 제한 대폭 완화
if w > 0 and w < 50 and h > 0 and h < 50:
    continue
```

**주의:** 쓰레기 이미지 증가 가능 (AI가 최종 필터 역할)

---

## 실행 순서

### Step 1: 진단 로깅 추가
1. [news_research.py](file:///C:/Users/KTY/Desktop/youtube-creator-platform-2/BE/test_news_research.py)에 위 4곳에 로그 추가
2. [test_news_research.py](file:///C:/Users/KTY/Desktop/youtube-creator-platform-2/BE/test_news_research.py) 실행
3. 로그 분석:
   - "원본 이미지 발견: 0개" → Phase 2 (로딩 개선)
   - "원본 이미지 발견: 5개, 중복 제거 후: 0개" → 중복 로직 버그
   - "중복 제거 후: 3개, AI 거부: 3개" → Phase 3 (필터 완화) 또는 AI 프롬프트 개선

### Step 2: 원인별 대응
- **스크롤/로딩 문제** → Phase 2 Option C (하이브리드) 적용
- **필터 문제** → Phase 3 (필터 완화) 적용
- **AI 거부 문제** → AI 프롬프트 개선 (별도 작업)

### Step 3: 최종 검증
- 연합뉴스, 뉴스1 기사에서 이미지 수집 확인
- 쓰레기 이미지 증가 여부 확인
- 성능 저하 여부 확인 (총 소요 시간)

---

## 예상 결과

### 최선의 경우
- 연합뉴스, 뉴스1에서도 이미지/차트 정상 수집
- 5개 기사 중 3~4개에서 시각 자료 확보

### 최악의 경우
- 일부 사이트는 구조적으로 불가능 (Intersection Observer + 동적 DOM)
- 해당 사이트는 포기하고 다른 언론사 우선 수집

---

## 참고 사항

### 현재 설정값
- `MAX_WORKERS`: 3
- `CRAWL_TIMEOUT`: 40초
- 스크롤 대기: 2초 × 5회 = 10초
- AI 분석 이미지: 5개/기사

### 성능 고려사항
- networkidle 적용 시 기사당 약 20초 소요 예상
- 5개 기사 × 20초 ÷ 3 workers = **약 35초** (현재 대비 +10초)
- OpenAI Rate Limit 여유 있음 (3 workers × 5 images = 15 동시 요청)

---

## 다음 작업 시 체크리스트

- [ ] Phase 1 로깅 추가
- [ ] 테스트 실행 및 로그 분석
- [ ] 원인 파악 후 Phase 2 또는 3 적용
- [ ] 최종 검증
- [ ] task.md 업데이트
