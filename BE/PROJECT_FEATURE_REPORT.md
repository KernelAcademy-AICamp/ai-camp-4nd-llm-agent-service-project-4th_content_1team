# 프로젝트 기능 상세 분석 보고서

## 1. 개요
현재 프로젝트는 **YouTube 크리에이터 지원 플랫폼**의 백엔드(`BE`)로, **FastAPI** 기반의 웹 서버와 **LangGraph** 기반의 AI 에이전트 시스템이 공존하는 형태입니다.

가장 눈에 띄는 점은 **"주제 추천(Topic Rec)"** 기능은 거의 완성되어 있으나, **"대본 작성(Writer)"** 및 **"썸네일 생성(Thumbnail)"** 기능은 뼈대만 잡혀 있거나 구현이 비어 있는 상태라는 것입니다.

---

## 2. 모듈별 구현 상태 상세

### A. 주제 추천 엔진 (`src/topic_rec`) - [✅ 구현 완료]
사용자 채널의 페르소나에 맞춰 트렌드를 수집하고 분석하여 매니저처럼 주제를 제안하는 핵심 모듈입니다.
- **상태**: **정상 동작** (로그 확인 완료)
- **주요 파일**:
    - `graph.py`: 수집 -> 처리 -> 클러스터링 -> 분석 -> 추천으로 이어지는 워크플로우 정의.
    - `nodes/trend_scout.py`: Reddit 등에서 트렌드 데이터를 수집하고 분류.
    - `nodes/recommender.py`: **Ollama(로컬 LLM)** 또는 **Gemini**를 사용하여 최종 주제를 추천. (현재 Ollama 연결 실패 시 자동 모드로 전환되는 안전장치 포함됨)
    - `nodes/clusterer.py`: 수집된 잡다한 정보들을 카테고리별로 묶어주는 역할.

### B. 뉴스 리서치 에이전트 (`src/script_gen/nodes/news_research.py`) - [✅ 고도화 완료]
단순 검색이 아니라, 실제 기사를 긁어오고 분석하는 기능이 강력하게 구현되어 있습니다.
- **상태**: **구현 완료 (매우 상세함)**
- **주요 기능**:
    1. **Deep Fetch**: 검색어당 15개의 기사를 수집하여 후보군 확보.
    2. **Smart Dedup**: 제목/내용 유사도를 따져 중복 기사를 제거하고 '알짜' 기사만 남김.
    3. **Crawling**: Playwright 브라우저를 띄워 Lazy Loading 이미지까지 긁어옴.
    4. **Fact Extraction**: 기사 내용을 분석해 통계, 명언, 핵심 사건을 정형화된 데이터(`structured_facts`)로 추출. (원래 별도 파일이던 기능이 여기 통합됨)

### C. 유튜브 데이터 서비스 (`app/services/youtube_service.py`) - [✅ 구현 완료]
실제 YouTube API와 연동하여 채널 통계를 분석하고 트렌드 영상을 검색하는 로직입니다.
- **상태**: **구현 완료**
- **주요 기능**:
    - **채널 동기화**: 내 채널의 구독자, 조회수 등을 DB에 저장.
    - **인기도 검색**: 단순 조회수가 아니라, '신선도(Recency)'와 '참여도(좋아요/댓글)'를 반영한 자체 알고리즘으로 진짜 뜨는 영상을 찾아냄.
    - **데이터 분석**: 시청자 성별, 연령대, 국가 등의 정밀 통계 지원.

---

## 3. 미구현 및 비어있는 모듈 (⚠️ 중요)

다음 파일들은 파일은 존재하지만 **내용이 비어있거나(0 byte)**, 선언만 되어 있습니다.

### A. 대본 작성기 (`src/script_gen`)
- **`writer.py`**: **비어있음.** 리서치한 내용을 바탕으로 실제 대본을 쓰는 로직이 아직 없습니다.
- **`fact_extractor.py`**: **비어있음.** (단, 이 기능은 `news_research.py` 내부로 통합되어 구현되었으므로 문제는 아님)
- **`graph.py`**: 비어있을 가능성 높음. 대본 생성 전체 흐름을 관장하는 파일이 누락되어 있습니다.

### B. 썸네일 생성기 (`src/thumbnail`)
- **`art_director.py`**: **비어있음.** 썸네일 기획을 담당하는 부분이 없습니다.
- **`nodes/*.py`**: 대부분 비어있을 것으로 추정됩니다.

---

## 4. 결론 및 제언
현재 **"트렌드 파악 -> 뉴스 심층 분석"** 까지의 앞단(Input)은 매우 탄탄하게 잡혀 있습니다. 하지만 **"대본 작성 -> 썸네일 생성"** 으로 이어지는 뒷단(Output) 작업이 필요한 상태입니다.

1.  **우선 순위**: `src/script_gen/nodes/writer.py`를 구현하여, 수집된 완벽한 뉴스 데이터(`news_research.py` 결과물)를 대본으로 바꾸는 작업이 1순위입니다.
2.  **테스트**: 주제 추천 엔진(`topic_rec`)은 `python -m src.topic_rec.graph` 명령어로 언제든 테스트 가능합니다.
