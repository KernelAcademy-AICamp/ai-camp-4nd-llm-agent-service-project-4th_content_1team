"""
Script Generation Graph - LangGraph ì›Œí¬í”Œë¡œìš°
ì£¼ì œ(Topic)ë¥¼ ì…ë ¥ë°›ì•„ ìœ íŠœë¸Œ ëŒ€ë³¸(Script)ì„ ìƒì„±í•˜ëŠ” ì „ì²´ íŒŒì´í”„ë¼ì¸

Workflow (Full Pipeline):
    User Input (Topic + Channel Profile)
    â†’ Planner (ëª©ì°¨/ì§ˆë¬¸ ìƒì„±)
    â”Œâ†’ News Research (ë‰´ìŠ¤ ìˆ˜ì§‘ + í¬ë¡¤ë§)
    â”‚   â†’ Article Analyzer (ê¸°ì‚¬ë³„ íŒ©íŠ¸Â·ì˜ê²¬Â·í•´ì„ ì¶”ì¶œ)
    â””â†’ YT Fetcher (ìœ íŠœë¸Œ ì˜ìƒ ê²€ìƒ‰)
        â†’ Competitor Analyzer (ê²½ìŸì‚¬ ë¶„ì„)
    â†’ Insight Builder (ì „ëµ ìˆ˜ë¦½)
    â†’ Writer (ëŒ€ë³¸ ì‘ì„±)
    â†’ Verifier (íŒ©íŠ¸ ì²´í¬ & ì¶œì²˜ ì •ë¦¬)
    â†’ Output (Verified ScriptDraft)

Note: Trend ScoutëŠ” topic_recommendationsë¡œ ëŒ€ì²´ë¨ (ì£¼ì„ì²˜ë¦¬)
"""

import logging
from langgraph.graph import StateGraph, END

from src.script_gen.state import ScriptGenState  # State ì •ì˜ import
from src.script_gen.nodes.intent_analyzer import intent_node
from src.script_gen.nodes.planner import planner_node
from src.script_gen.nodes.news_research import news_research_node
from src.script_gen.nodes.article_analyzer import article_analyzer_node
from src.script_gen.nodes.yt_fetcher import yt_fetcher_node
from src.script_gen.nodes.competitor_anal import competitor_anal_node
from src.script_gen.nodes.insight_builder import insight_builder_node
from src.script_gen.nodes.writer import writer_node
from src.script_gen.nodes.verifier import verifier_node
# from src.script_gen.nodes.trend_scout import trend_scout_node  # ì£¼ì„ì²˜ë¦¬: topic_recommendationsë¡œ ëŒ€ì²´

logger = logging.getLogger(__name__)


# =============================================================================
# Graph Construction
# =============================================================================

def create_script_gen_graph():
    """Script Generation Graph ìƒì„± (ì „ì²´ íŒŒì´í”„ë¼ì¸)"""

    # 1. Graph ì´ˆê¸°í™”
    workflow = StateGraph(ScriptGenState)

    # 2. ë…¸ë“œ ì¶”ê°€
    workflow.add_node("intent_analyzer", intent_node)
    workflow.add_node("planner", planner_node)
    workflow.add_node("news_research", news_research_node)
    workflow.add_node("article_analyzer", article_analyzer_node)  # ê¸°ì‚¬ ì‹¬ì¸µ ë¶„ì„
    workflow.add_node("yt_fetcher", yt_fetcher_node)
    workflow.add_node("competitor_anal", competitor_anal_node)
    workflow.add_node("insight_builder", insight_builder_node)
    workflow.add_node("writer", writer_node)
    workflow.add_node("verifier", verifier_node)

    # 3. ì—£ì§€ ì—°ê²°
    workflow.set_entry_point("intent_analyzer")
    workflow.add_edge("intent_analyzer", "planner")

    # Planner í›„ ë³‘ë ¬ ì‹¤í–‰: News Research ì™€ YT Fetcher
    workflow.add_edge("planner", "news_research")
    workflow.add_edge("planner", "yt_fetcher")

    # News Research â†’ Article Analyzer (ê¸°ì‚¬ ìˆ˜ì§‘ í›„ íŒ©íŠ¸Â·ì˜ê²¬ ì¶”ì¶œ)
    workflow.add_edge("news_research", "article_analyzer")

    # YT Fetcher â†’ Competitor Analyzer
    workflow.add_edge("yt_fetcher", "competitor_anal")

    # Article Analyzer ì™€ Competitor Analyzer ëª¨ë‘ ì™„ë£Œ í›„ Insight Builder
    # (LangGraph ê°€ ë‘ ì„ í–‰ ë…¸ë“œë¥¼ ìë™ìœ¼ë¡œ ê¸°ë‹¤ë¦¼)
    workflow.add_edge("article_analyzer", "insight_builder")
    workflow.add_edge("competitor_anal", "insight_builder")

    workflow.add_edge("insight_builder", "writer")
    workflow.add_edge("writer", "verifier")
    workflow.add_edge("verifier", END)

    # 4. ì»´íŒŒì¼
    app = workflow.compile()

    logger.info("Script Generation Graph ìƒì„± ì™„ë£Œ (Full Pipeline: 9 nodes)")
    return app


# =============================================================================
# Execution Function
# =============================================================================

# =============================================================================
# ë…¸ë“œ ì´ë¦„ â†’ ì‚¬ìš©ì í‘œì‹œìš© ë§¤í•‘
# =============================================================================

PIPELINE_STEPS = [
    {"key": "intent_analyzer",  "label": "ì‹œì²­ì ì˜ë„ ë¶„ì„",                   "emoji": "ğŸ¯", "nodes": ["intent_analyzer"]},
    {"key": "planner",          "label": "ì½˜í…ì¸  ê¸°íšì•ˆ ì‘ì„±",                 "emoji": "ğŸ“‹", "nodes": ["planner"]},
    {"key": "research",         "label": "ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜ì§‘ ë° ìœ íŠœë¸Œ ì˜ìƒ ê²€ìƒ‰", "emoji": "ğŸ“°", "nodes": ["news_research", "yt_fetcher"]},
    {"key": "analysis",         "label": "ê¸°ì‚¬ ì‹¬ì¸µ ë¶„ì„ ë° ê²½ìŸ ì˜ìƒ ë¶„ì„",   "emoji": "ğŸ”", "nodes": ["article_analyzer", "competitor_anal"]},
    {"key": "insight_builder",  "label": "ì „ëµ ì¸ì‚¬ì´íŠ¸ ìˆ˜ë¦½",                 "emoji": "ğŸ’¡", "nodes": ["insight_builder"]},
    {"key": "writer",           "label": "ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±",                      "emoji": "âœï¸", "nodes": ["writer"]},
    {"key": "verifier",         "label": "íŒ©íŠ¸ ì²´í¬ ê²€ì¦",                     "emoji": "âœ…", "nodes": ["verifier"]},
]

# ë…¸ë“œ ì´ë¦„ â†’ ìŠ¤í… key ì—­ë§¤í•‘
_NODE_TO_STEP = {}
for _step in PIPELINE_STEPS:
    for _node in _step["nodes"]:
        _NODE_TO_STEP[_node] = _step["key"]

ALL_NODE_NAMES = list(_NODE_TO_STEP.keys())


async def generate_script(
    topic: str,
    channel_profile: dict,
    topic_request_id: str = None,
    progress_callback=None,
) -> dict:
    """
    ì£¼ì œë¥¼ ì…ë ¥ë°›ì•„ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.

    Args:
        topic: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì£¼ì œ (ì˜ˆ: "AI ë°˜ë„ì²´ ì‹œì¥ ë™í–¥")
        channel_profile: ì±„ë„ ì •ë³´ (name, tone, target_audience ë“±)
        topic_request_id: ìš”ì²­ ID (ì„ íƒ)
        progress_callback: ì§„í–‰ ìƒí™© ì½œë°± (step_key, status) â†’ Celery update_stateìš©

    Returns:
        ScriptDraft dict (ìµœì¢… ëŒ€ë³¸, news_data, competitor_data í¬í•¨)
    """
    import uuid

    if not topic_request_id:
        topic_request_id = f"trq_{uuid.uuid4().hex[:8]}"

    # ì´ˆê¸° State êµ¬ì„±
    initial_state = {
        "topic": topic,
        "topic_request_id": topic_request_id,
        "channel_profile": channel_profile,
        "intent_analysis": {},
        "trend_data": {},
        "content_brief": {},
        "news_data": {},
        "insight_pack": {},
        "script_draft": {},
        "competitor_data": None,
        "youtube_data": None
    }

    logger.info(f"Script Generation ì‹œì‘: {topic!r}")
    app = create_script_gen_graph()

    try:
        # astream_eventsë¡œ ë…¸ë“œ ì§„ì…/ì™„ë£Œ ì´ë²¤íŠ¸ë¥¼ ì‹¤ì‹œê°„ ìˆ˜ì‹ 
        final_state = None
        completed_nodes = set()    # ê°œë³„ ë…¸ë“œ ì™„ë£Œ ì¶”ì 
        completed_steps = []       # UI ìŠ¤í… ì™„ë£Œ ì¶”ì 

        def _notify(current_step_key, message):
            """ì§„í–‰ ìƒí™©ì„ ì½œë°±ìœ¼ë¡œ ì „ë‹¬"""
            if progress_callback:
                progress_callback(
                    current_step=current_step_key,
                    message=message,
                    completed_steps=list(completed_steps),
                )

        async for event in app.astream_events(initial_state, version="v2"):
            kind = event.get("event", "")
            name = event.get("name", "")

            if name not in ALL_NODE_NAMES:
                # ìµœì¢… ê²°ê³¼ ìˆ˜ì§‘
                if kind == "on_chain_end" and event.get("data", {}).get("output"):
                    output = event["data"]["output"]
                    if isinstance(output, dict) and "script_draft" in output:
                        final_state = output
                continue

            step_key = _NODE_TO_STEP[name]
            step_info = next(s for s in PIPELINE_STEPS if s["key"] == step_key)

            # ë…¸ë“œ ì‹œì‘ ì´ë²¤íŠ¸
            if kind == "on_chain_start":
                if step_key not in completed_steps:
                    _notify(step_key, f"{step_info['emoji']} {step_info['label']} ì¤‘...")
                logger.info(f"â–¶ Node ì‹œì‘: {name}")

            # ë…¸ë“œ ì™„ë£Œ ì´ë²¤íŠ¸
            elif kind == "on_chain_end":
                completed_nodes.add(name)
                logger.info(f"âœ“ Node ì™„ë£Œ: {name}")

                # ê·¸ë£¹ ë‚´ ëª¨ë“  ë…¸ë“œê°€ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
                group_nodes = set(step_info["nodes"])
                if group_nodes.issubset(completed_nodes) and step_key not in completed_steps:
                    completed_steps.append(step_key)
                    _notify(step_key, f"{step_info['emoji']} {step_info['label']} ì™„ë£Œ")

        if final_state is None:
            raise RuntimeError("íŒŒì´í”„ë¼ì¸ì´ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        logger.info("Script Generation ì™„ë£Œ")

        # ì „ì²´ íŒŒì´í”„ë¼ì¸ ê²°ê³¼
        result = final_state["script_draft"].copy()
        result["verifier_output"] = final_state.get("verifier_output")
        result["news_data"] = final_state.get("news_data")
        result["competitor_data"] = final_state.get("competitor_data")
        return result

    except Exception as e:
        logger.error(f"Script Generation ì‹¤íŒ¨: {e}", exc_info=True)
        raise


# =============================================================================
# CLI Test (ê°œë°œìš©)
# =============================================================================

if __name__ == "__main__":
    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_topic = "AI ë°˜ë„ì²´ ì‹œì¥ì˜ ìµœì‹  ë™í–¥"
    test_channel = {
        "name": "í…Œí¬ ì¸ì‚¬ì´íŠ¸",
        "tone": "ë¶„ì„ì ì´ì§€ë§Œ ì‰¬ìš´",
        "target_audience": "IT ê´€ì‹¬ ì¼ë°˜ì¸",
        "category": "Technology"
    }
    
    import asyncio
    print(f"ğŸš€ í…ŒìŠ¤íŠ¸ ì‹œì‘: {test_topic}")
    result = asyncio.run(generate_script(test_topic, test_channel))
    
    print("\nâœ… ëŒ€ë³¸ ìƒì„± ì™„ë£Œ!")
    print(f"- Script ID: {result.get('script_draft_id')}")
    print(f"- ì±•í„° ìˆ˜: {len(result.get('script', {}).get('chapters', []))}")
    print(f"- Hook: {result.get('script', {}).get('hook', {}).get('text', '')[:100]}...")
