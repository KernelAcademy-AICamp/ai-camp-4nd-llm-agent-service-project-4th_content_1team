"""
Planner Node - ì½˜í…ì¸  ê¸°íš ì—ì´ì „íŠ¸

Intent Analyzer ê²°ê³¼ë¥¼ ë°›ì•„:
  1. content_angle â€” intent_analyzerê°€ ì œì‹œí•œ ì•µê¸€ì„ reader ì‹¬ë¦¬ ê¸°ë°˜ìœ¼ë¡œ ë””ë²¨ë¡­
  2. research_plan  â€” sub_topics search_hintë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¦¬ì„œì¹˜ í‚¤ì›Œë“œ + í™œìš©ë²• êµ¬ì„±
                      (í•„ìš” ì‹œ ë””ë²¨ë¡­ëœ ì•µê¸€ì— ë§ì¶° í‚¤ì›Œë“œ ì¶”ê°€)
                      youtube_keywords: ìœ ì‚¬ ìœ íŠœë¸Œ ì˜ìƒ ê²€ìƒ‰ìš© 2ê°œ

Downstream í˜¸í™˜ í•„ë“œ:
  - researchPlan.newsQuery â†’ news_research_node
  - search_queries         â†’ yt_fetcher_node
"""
from typing import Dict, Any, Optional, List
from langchain_openai import ChatOpenAI
import json
import logging
import re
import asyncio

logger = logging.getLogger(__name__)

MAX_RETRIES = 3
OPENAI_MODEL = "gpt-4o"


class ValidationError(Exception):
    """Planner ì¶œë ¥ ê²€ì¦ ì‹¤íŒ¨"""
    pass


# =============================================================================
# ë©”ì¸ ë…¸ë“œ í•¨ìˆ˜
# =============================================================================

async def planner_node(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    Intent Analyzer ê²°ê³¼ë¥¼ ì´ì–´ë°›ì•„ ì½˜í…ì¸  ì•µê¸€(1ê°œ)ê³¼ ë¦¬ì„œì¹˜ í”Œëœì„ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        state: ScriptGenState (topic, channel_profile, intent_analysis í¬í•¨)

    Returns:
        {"content_brief": {"content_angle": {...}, "research_plan": {...}}}
    """
    topic = state.get("topic")
    channel_profile = state.get("channel_profile", {})
    intent_analysis = state.get("intent_analysis") or {}

    if not topic:
        raise ValueError("Topic is required in state")

    last_error = None

    for attempt in range(MAX_RETRIES):
        try:
            logger.info(f"[Planner] ì‹œë„ {attempt + 1}/{MAX_RETRIES}")

            prompt = _build_planner_prompt(
                topic=topic,
                channel_profile=channel_profile,
                intent_analysis=intent_analysis,
                attempt=attempt,
                last_error=last_error,
            )

            llm = ChatOpenAI(model=OPENAI_MODEL, temperature=0.4)
            response = await llm.ainvoke(prompt)

            content_brief = _parse_llm_response(response.content)
            _validate_content_brief(content_brief)

            # downstream ë…¸ë“œìš© í˜¸í™˜ í•„ë“œ ì¶”ê°€
            _derive_downstream_fields(content_brief, state)

            logger.info("âœ… [Planner] ì„±ê³µ: ì•µê¸€ ë””ë²¨ë¡­ + ë¦¬ì„œì¹˜ í”Œëœ ìƒì„± ì™„ë£Œ")
            _log_result(topic, content_brief)
            return {"content_brief": content_brief}

        except ValidationError as e:
            last_error = str(e)
            logger.warning(f"âš ï¸ [Planner] ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {e}")
            if attempt == MAX_RETRIES - 1:
                raise RuntimeError(
                    f"ì½˜í…ì¸  ê¸°íšì•ˆ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”. (ì˜¤ë¥˜: {e})"
                )
            wait_time = 2 ** attempt
            logger.info(f"[Planner] {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
            await asyncio.sleep(wait_time)

        except json.JSONDecodeError as e:
            last_error = f"JSON parse error: {str(e)}"
            logger.warning(f"âš ï¸ [Planner] JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            if attempt == MAX_RETRIES - 1:
                raise RuntimeError("LLMì´ ì˜¬ë°”ë¥¸ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            await asyncio.sleep(2 ** attempt)

    raise RuntimeError("Unexpected error in planner_node")


# =============================================================================
# í—¬í¼: downstream í˜¸í™˜ í•„ë“œ ì¶”ì¶œ
# =============================================================================

def _derive_downstream_fields(content_brief: Dict, state: Dict) -> None:
    """
    ìƒˆ êµ¬ì¡°ì—ì„œ downstream ë…¸ë“œê°€ í•„ìš”ë¡œ í•˜ëŠ” í•„ë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

    - researchPlan.newsQuery  â†’ news_research_node
    - search_queries          â†’ yt_fetcher_node
    """
    research_plan = content_brief.get("research_plan", {})

    # â”€â”€ news_research_node â”€â”€
    sources = research_plan.get("sources", [])
    news_keywords = [s["keyword"] for s in sources if s.get("keyword")]
    content_brief["researchPlan"] = {
        "newsQuery": news_keywords,
        "freshnessDays": 30,
    }

    # â”€â”€ yt_fetcher_node â”€â”€
    content_brief["search_queries"] = research_plan.get("youtube_keywords", [])


# =============================================================================
# í—¬í¼: í”„ë¡¬í”„íŠ¸ ìƒì„±
# =============================================================================

def _build_planner_prompt(
    topic: str,
    channel_profile: Dict,
    intent_analysis: Dict,
    attempt: int = 0,
    last_error: Optional[str] = None,
) -> str:
    """
    Planner í”„ë¡¬í”„íŠ¸ ìƒì„±.

    êµ¬ì„±:
        1. Role & Task
        2. Intent Analyzer ê²°ê³¼ (í•µì‹¬ ì…ë ¥)
        3. ì±„ë„ í˜ë¥´ì†Œë‚˜ (ë³´ì¡° ì…ë ¥)
        4. ì¶œë ¥ í˜•ì‹ ì§€ì‹œ
    """

    # â”€â”€ Intent Analyzer ê²°ê³¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ì´ ë¸”ë¡ì´ Plannerì˜ í•µì‹¬ ì…ë ¥
    intent_block = ""
    sub_topics_hint = []
    if intent_analysis:
        intent_mix = intent_analysis.get("intent_mix", {})
        sub_topics = intent_analysis.get("sub_topics", [])
        base_angle = intent_analysis.get("content_angle", "")

        intent_block = "\n\n## ğŸ“Š Intent Analyzer ê²°ê³¼ (í•µì‹¬ ì…ë ¥)\n"
        intent_block += f"- ê¸°ë³¸ ì»¨í…ì¸  ì•µê¸€: **{base_angle}** â† ì´ê²ƒì„ ë””ë²¨ë¡­í•  ê²ƒ\n"
        intent_block += f"- í•µì‹¬ ì§ˆë¬¸: {intent_analysis.get('core_question', '')}\n"
        intent_block += f"- ì‹œì²­ì ê³ ë¯¼: {intent_analysis.get('reader_pain_point', '')}\n"
        intent_block += f"- ì‹œì²­ì ìš•êµ¬: {intent_analysis.get('reader_desire', '')}\n"
        intent_block += (
            f"- ì˜ë„ ë¹„ìœ¨: ì •ë³´í˜• {intent_mix.get('informational', 0)}% / "
            f"ê°ì„±í˜• {intent_mix.get('emotional', 0)}% / "
            f"ì‹¤í–‰í˜• {intent_mix.get('actionable', 0)}%\n"
        )
        if sub_topics:
            intent_block += "- í•˜ìœ„ ì£¼ì œ ë° ë¦¬ì„œì¹˜ í‚¤ì›Œë“œ (research_plan ì‹œì‘ì ):\n"
            for st in sub_topics:
                hint = st.get("search_hint", "")
                intent_block += (
                    f"  â€¢ [{st.get('topic', '')}] {st.get('reason', '')} "
                    f"â†’ ê²€ìƒ‰íŒíŠ¸: \"{hint}\"\n"
                )
                if hint:
                    sub_topics_hint.append(hint)

    # â”€â”€ ì±„ë„ í˜ë¥´ì†Œë‚˜ (ë³´ì¡°) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    persona_block = "\n\n## ğŸ™ï¸ ì±„ë„ í˜ë¥´ì†Œë‚˜ (ì°¸ê³ )\n"
    persona_block += f"- ì±„ë„ëª…: {channel_profile.get('name', 'Unknown')}\n"
    persona_block += f"- íƒ€ê²Ÿ ì‹œì²­ì: {channel_profile.get('target_audience', 'ì¼ë°˜ ì‹œì²­ì')}\n"
    if channel_profile.get("content_style"):
        persona_block += f"- ì½˜í…ì¸  ìŠ¤íƒ€ì¼: {channel_profile['content_style']}\n"
    if channel_profile.get("differentiator"):
        persona_block += f"- ì°¨ë³„ì : {channel_profile['differentiator']}\n"

    # â”€â”€ ì¶œë ¥ í˜•ì‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    hint_example = sub_topics_hint[0] if sub_topics_hint else "AI ì½”ë”© ë„êµ¬ ìƒì‚°ì„± ì—°êµ¬"
    format_instruction = f"""

## ğŸ“‹ ì¶œë ¥ í˜•ì‹ (ì´ JSONë§Œ ë°˜í™˜)

```json
{{
  "content_angle": {{
    "angle": "ê¸°ë³¸ ì•µê¸€ì„ reader ì‹¬ë¦¬ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì²´í™”í•œ ìµœì¢… ì•µê¸€",
    "description": "ì´ ì•µê¸€ë¡œ ì ‘ê·¼í•˜ëŠ” ì´ìœ  â€” ì‹œì²­ì ê³ ë¯¼ê³¼ ìš•êµ¬ì— ì–´ë–»ê²Œ ì‘ë‹µí•˜ëŠ”ì§€ ì„¤ëª…",
    "hook": "ì´ ì•µê¸€ë¡œ ì‹œì²­ìë¥¼ ì‚¬ë¡œì¡ì„ ì²« ë§ˆë”” (í›… ë¬¸ì¥)"
  }},
  "research_plan": {{
    "sources": [
      {{
        "keyword": "{hint_example}",
        "how_to_use": "ì˜ìƒì˜ ì–´ëŠ ë¶€ë¶„ì—ì„œ, ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ í™œìš©í• ì§€"
      }}
    ],
    "youtube_keywords": [
      "ë¹„ìŠ·í•œ ì£¼ì œ ìœ íŠœë¸Œ ê²€ìƒ‰ í‚¤ì›Œë“œ 1",
      "ë¹„ìŠ·í•œ ì£¼ì œ ìœ íŠœë¸Œ ê²€ìƒ‰ í‚¤ì›Œë“œ 2"
    ]
  }}
}}
```

## âœ… ì‘ì„± ê·œì¹™

**content_angle:**
- `angle`: Intent Analyzerì˜ content_angleì„ ê·¸ëŒ€ë¡œ ì“°ì§€ ë§ê³ , core_question + reader_pain_point + reader_desireë¥¼ ëª¨ë‘ ë°˜ì˜í•˜ì—¬ ë” êµ¬ì²´ì ìœ¼ë¡œ ë””ë²¨ë¡­
- `description`: "ì™œ ì´ ì•µê¸€ì¸ê°€?" â€” ì‹œì²­ì ê³ ë¯¼ê³¼ ìš•êµ¬ì— ì–´ë–»ê²Œ ì‘ë‹µí•˜ëŠ”ì§€ ëª…í™•íˆ
- `hook`: ì‹œì²­ìê°€ ì˜ìƒì„ í´ë¦­í•˜ê²Œ ë§Œë“¤ ì²« ë§ˆë”” (ì§ˆë¬¸í˜• ë˜ëŠ” ë„ë°œí˜•)

**research_plan.sources:**
- Intent Analyzerì˜ í•˜ìœ„ ì£¼ì œ ê²€ìƒ‰íŒíŠ¸ë¥¼ **ë°˜ë“œì‹œ í¬í•¨** (ì‹œì‘ì )
- ë””ë²¨ë¡­ëœ ì•µê¸€ì— ë§ê²Œ **ì¶”ê°€ í‚¤ì›Œë“œ ë³´ì™„ ê°€ëŠ¥**
- ê° ì†ŒìŠ¤ì˜ `how_to_use`: ì˜ìƒì—ì„œ **ì–´ëŠ ì„¹ì…˜ì—ì„œ ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ** ì“¸ì§€ êµ¬ì²´ì ìœ¼ë¡œ
- ìµœì†Œ 3ê°œ, ê¶Œì¥ 5~7ê°œ
- âš ï¸ `keyword`ëŠ” **ë‹¨ì¼ ê²€ìƒ‰ì–´**ë§Œ ì‚¬ìš© â€” ì‰¼í‘œ(,) ì ˆëŒ€ ê¸ˆì§€, ì§§ê³  ëª…í™•í•˜ê²Œ (ì˜ˆ: "Claude Code í™œìš©ë²•", "AI ì½”ë”© ë„êµ¬ ë¹„êµ")

**research_plan.youtube_keywords:**
- ì •í™•íˆ 2ê°œ
- ë¹„ìŠ·í•œ ì£¼ì œì˜ ë‹¤ë¥¸ ìœ íŠœë¸Œ ì˜ìƒì„ ì°¾ê¸° ìœ„í•œ í•œêµ­ì–´ ê²€ìƒ‰ì–´

**ê³µí†µ:**
- ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” í•œêµ­ì–´
- ìˆœìˆ˜ JSONë§Œ ë°˜í™˜ (ì„¤ëª… ì—†ì´)
"""

    base_prompt = f"""ë‹¹ì‹ ì€ ìœ íŠœë¸Œ ì½˜í…ì¸  ì „ëµê°€ì…ë‹ˆë‹¤.
Intent Analyzerê°€ ë¶„ì„í•œ ê²°ê³¼ë¥¼ ë°›ì•„, ì‹œì²­ì ì‹¬ë¦¬ì— ìµœì í™”ëœ ì½˜í…ì¸  ì•µê¸€ê³¼ ë¦¬ì„œì¹˜ í”Œëœì„ ìƒì„±í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ì œ
{topic}
{intent_block}{persona_block}

## ğŸ“Œ ì‘ì—… ì§€ì‹œ

**STEP 1: content_angle ë””ë²¨ë¡­**
- Intent Analyzerì˜ `content_angle`(ê¸°ë³¸ ì•µê¸€)ì„ ì¶œë°œì ìœ¼ë¡œ ì‚¼ì•„
- `core_question`ì´ ê¶ê¸ˆì¦ì„ ìœ ë°œí•˜ë„ë¡, `reader_pain_point`ê°€ í•´ì†Œë˜ë„ë¡, `reader_desire`ê°€ ì¶©ì¡±ë˜ë„ë¡
- ì„¸ ìš”ì†Œë¥¼ í†µí•©í•˜ì—¬ ë” êµ¬ì²´ì ì´ê³  ì„¤ë“ë ¥ ìˆëŠ” ì•µê¸€ë¡œ ë°œì „ì‹œí‚¤ì„¸ìš”
- ì˜ë„ ë¹„ìœ¨(ì •ë³´/ê°ì„±/ì‹¤í–‰)ì— ë§ê²Œ ì•µê¸€ì˜ toneì„ ì¡°ì •í•˜ì„¸ìš”

**STEP 2: research_plan ì‘ì„±**
- í•˜ìœ„ ì£¼ì œ ê²€ìƒ‰íŒíŠ¸ë¥¼ ë¨¼ì € sourcesì— í¬í•¨ (ê°ê° how_to_use ì‘ì„±)
- ë””ë²¨ë¡­ëœ ì•µê¸€ì„ ë” ì˜ ë’·ë°›ì¹¨í•˜ê¸° ìœ„í•´ í•„ìš”í•œ í‚¤ì›Œë“œ ì¶”ê°€
- youtube_keywords: ì´ ì£¼ì œì™€ ë¹„ìŠ·í•œ ì˜ìƒì„ ì°¾ì„ ìˆ˜ ìˆëŠ” ê²€ìƒ‰ì–´ 2ê°œ
{format_instruction}

ì£¼ì œ "{topic}"ì— ëŒ€í•œ ê¸°íšì•ˆì„ JSONìœ¼ë¡œë§Œ ë°˜í™˜í•˜ì„¸ìš”:"""

    # â”€â”€ ì¬ì‹œë„ í”¼ë“œë°± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if attempt > 0 and last_error:
        return f"""[ì¬ì‹œë„ {attempt + 1}íšŒì°¨]
ì´ì „ ì‘ë‹µ ì˜¤ë¥˜: {last_error}

ìˆ˜ì • í•„ìˆ˜:
- content_angle: angle / description / hook ëª¨ë‘ ë¹„ì–´ìˆìœ¼ë©´ ì•ˆ ë¨
- research_plan.sources: ìµœì†Œ 3ê°œ, ê°ê° keyword + how_to_use í¬í•¨
- research_plan.youtube_keywords: ì •í™•íˆ 2ê°œ

{base_prompt}"""

    return base_prompt


# =============================================================================
# í—¬í¼: JSON íŒŒì‹±
# =============================================================================

def _parse_llm_response(response_text: str) -> Dict:
    """LLM ì‘ë‹µì—ì„œ JSON ê°ì²´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""

    # ì „ëµ 1: ì½”ë“œ ë¸”ë¡ (```json ... ```)
    code_block = re.search(r"```(?:json)?\s*(\{.*?\})\s*```", response_text, re.DOTALL)
    if code_block:
        try:
            return json.loads(code_block.group(1))
        except json.JSONDecodeError:
            pass

    # ì „ëµ 2: ì¤‘ê´„í˜¸ ê· í˜• íƒìƒ‰
    start_idx = response_text.find("{")
    if start_idx != -1:
        depth = 0
        for i in range(start_idx, len(response_text)):
            if response_text[i] == "{":
                depth += 1
            elif response_text[i] == "}":
                depth -= 1
                if depth == 0:
                    try:
                        return json.loads(response_text[start_idx : i + 1])
                    except json.JSONDecodeError:
                        break

    # ì „ëµ 3: ì „ì²´ í…ìŠ¤íŠ¸
    try:
        return json.loads(response_text.strip())
    except json.JSONDecodeError:
        logger.error(f"[Planner] JSON íŒŒì‹± ì‹¤íŒ¨: {response_text[:200]}...")
        raise json.JSONDecodeError("Could not extract valid JSON", response_text, 0)


# =============================================================================
# í—¬í¼: ê²€ì¦
# =============================================================================

def _validate_content_brief(brief: Dict) -> None:
    """
    Planner ì¶œë ¥ ìœ íš¨ì„± ê²€ì¦.
    ì‹¤íŒ¨ ì‹œ ValidationError ë°œìƒ.
    """
    # í•„ìˆ˜ ìµœìƒìœ„ í•„ë“œ
    for field in ["content_angle", "research_plan"]:
        if field not in brief:
            raise ValidationError(f"í•„ìˆ˜ í•„ë“œ ì—†ìŒ: {field}")

    # content_angle: ë‹¨ì¼ ê°ì²´
    angle = brief.get("content_angle", {})
    if not isinstance(angle, dict):
        raise ValidationError("content_angleì€ ê°ì²´ì—¬ì•¼ í•©ë‹ˆë‹¤")
    for sub in ["angle", "description", "hook"]:
        if not angle.get(sub, "").strip():
            raise ValidationError(f"content_angle.{sub} ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")

    # research_plan êµ¬ì¡°
    rp = brief.get("research_plan", {})
    if not isinstance(rp, dict):
        raise ValidationError("research_planì€ ê°ì²´ì—¬ì•¼ í•©ë‹ˆë‹¤")

    # sources: ìµœì†Œ 3ê°œ, ê° í•­ëª©ì— keyword + how_to_use
    sources = rp.get("sources", [])
    if not isinstance(sources, list) or len(sources) < 3:
        raise ValidationError(
            f"research_plan.sourcesëŠ” ìµœì†Œ 3ê°œì—¬ì•¼ í•©ë‹ˆë‹¤ (í˜„ì¬: {len(sources)}ê°œ)"
        )
    for i, src in enumerate(sources, 1):
        for sub in ["keyword", "how_to_use"]:
            if not src.get(sub, "").strip():
                raise ValidationError(
                    f"research_plan.sources[{i}].{sub} ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"
                )

    # youtube_keywords: ì •í™•íˆ 2ê°œ
    yt_kw = rp.get("youtube_keywords", [])
    if not isinstance(yt_kw, list) or len(yt_kw) != 2:
        raise ValidationError(
            f"research_plan.youtube_keywordsëŠ” ì •í™•íˆ 2ê°œì—¬ì•¼ í•©ë‹ˆë‹¤ (í˜„ì¬: {len(yt_kw)}ê°œ)"
        )
    for kw in yt_kw:
        if not str(kw).strip():
            raise ValidationError("research_plan.youtube_keywordsì— ë¹ˆ í•­ëª©ì´ ìˆìŠµë‹ˆë‹¤")


# =============================================================================
# í—¬í¼: ë¡œê¹…
# =============================================================================

def _log_result(topic: str, brief: Dict) -> None:
    """Planner ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ í˜•ì‹ìœ¼ë¡œ ë¡œê¹…í•©ë‹ˆë‹¤."""
    angle = brief.get("content_angle", {})
    sources = brief.get("research_plan", {}).get("sources", [])
    yt_kw = brief.get("research_plan", {}).get("youtube_keywords", [])

    lines = [
        f"[Planner] ê²°ê³¼ â€” {topic!r}",
        f"  ì•µê¸€: [{angle.get('angle', '')}]",
        f"  ì„¤ëª…: {angle.get('description', '')}",
        f"  í›…:   {angle.get('hook', '')}",
        f"  ë¦¬ì„œì¹˜ ì†ŒìŠ¤ ({len(sources)}ê°œ):",
    ]
    for s in sources:
        lines.append(f"    â€¢ \"{s.get('keyword', '')}\" â†’ {s.get('how_to_use', '')}")
    lines.append(f"  ìœ íŠœë¸Œ í‚¤ì›Œë“œ: {yt_kw}")
    logger.info("\n".join(lines))
