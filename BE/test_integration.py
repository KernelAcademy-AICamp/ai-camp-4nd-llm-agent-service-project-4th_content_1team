import logging
import json
import os
from src.script_gen.nodes.trend_scout import trend_scout_node
from src.script_gen.nodes.planner import planner_node
from src.script_gen.nodes.news_research import news_research_node
from dotenv import load_dotenv

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_integration_pipeline():
    """
    [í†µí•© í…ŒìŠ¤íŠ¸]
    Trend Scout -> Planner -> News Research (Optional)
    ì „ì²´ íë¦„ì´ ìœ ê¸°ì ìœ¼ë¡œ ì—°ê²°ë˜ëŠ”ì§€ ê²€ì¦í•©ë‹ˆë‹¤.
    """
    load_dotenv()
    
    # 1. ì´ˆê¸° ìƒíƒœ ì„¤ì • (ì‚¬ìš©ì ì…ë ¥ ê°€ì •)
    initial_state = {
        "channel_profile": {
            "name": "Tech Future",
            "category": "Technology & AI",
            "target_audience": "Tech enthusiasts, Early adopters",
            "average_duration": 10,
            "content_style": "Deep Dive Analysis with cynicism" # ì•½ê°„ ì‚ë”±í•œ ë¶„ì„ ìŠ¤íƒ€ì¼
        },
        # topicì€ Trend Scoutê°€ ì°¾ì•„ì¤„ ê²ƒì´ë¯€ë¡œ ë¹„ì›Œë‘  (í˜¹ì€ ê´€ì‹¬ì‚¬ ì„¤ì •)
        "channel_profile_interests": ["Artificial Intelligence", "Gadgets", "Future Tech"]
    }
    
    logger.info("ğŸ¬ [Step 1] Trend Scout: íŠ¸ë Œë“œ ë°œêµ´ ë° ì—¬ë¡  ìˆ˜ì§‘ ì‹œì‘")
    state_after_trend = trend_scout_node(initial_state)
    
    # Trend Scout ê²°ê³¼ í™•ì¸
    topic = state_after_trend.get("topic")
    trend_data = state_after_trend.get("trend_analysis", {})
    
    if not topic:
        logger.error("âŒ Trend Scoutê°€ ì£¼ì œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨.")
        return

    logger.info(f"âœ… ì„ ì •ëœ ì£¼ì œ: {topic}")
    logger.info(f"âœ… íŠ¸ë Œë“œ ë¶„ì„ ë°ì´í„° í™•ë³´: í‚¤ì›Œë“œ {len(trend_data.get('keywords', []))}ê°œ")
    if "top_comments" in trend_data:
        logger.info(f"âœ… ìˆ˜ì§‘ëœ ë² ìŠ¤íŠ¸ ëŒ“ê¸€: {len(trend_data['top_comments'])}ê°œ í™•ì¸ë¨")
        # ëŒ“ê¸€ ìƒ˜í”Œ ì¶œë ¥ (ë²ˆì—­ ë° ì¢‹ì•„ìš” í™•ì¸)
        for i, c in enumerate(trend_data["top_comments"][:2]):
            logger.info(f"   ğŸ’¬ Comment #{i+1}: {c[:50]}...")

    print("\n" + "="*50 + "\n")

    # 2. Planner ì‹¤í–‰ (Trend Data ë°˜ì˜)
    logger.info("ğŸ¬ [Step 2] Planner: ì—¬ë¡  ë°˜ì˜ ê¸°íšì•ˆ ìˆ˜ë¦½ ì‹œì‘")
    
    # Plannerê°€ trend_analysisë¥¼ ì“¸ ìˆ˜ ìˆë„ë¡ stateê°€ ì˜ ì „ë‹¬ë˜ëŠ”ì§€ í™•ì¸
    # (planner_node ë‚´ë¶€ì—ì„œ state['trend_analysis']ë¥¼ ì°¸ì¡°í•˜ë„ë¡ ìˆ˜ì •í–ˆëŠ”ì§€ ì²´í¬ í•„ìš”.
    #  ì•„ê¹Œ _build_planner_prompt ì¸ìë§Œ ì¶”ê°€í–ˆì§€, node í•¨ìˆ˜ ìì²´ì—ì„œ ë„˜ê²¨ì£¼ëŠ” ë¡œì§ì„ í™•ì¸í•´ì•¼ í•¨.
    #  -> ë§Œì•½ planner.pyì˜ planner_node í•¨ìˆ˜ì—ì„œ trend_analysisë¥¼ ì¶”ì¶œí•´ì„œ _build_planner_promptì— ì•ˆ ë„˜ê²¨ì£¼ë©´ ë°˜ì˜ ì•ˆ ë¨.
    #  -> **ì¤‘ìš”**: planner.pyì˜ node í•¨ìˆ˜ ìˆ˜ì •ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ. ì¼ë‹¨ ëŒë ¤ë³´ê³  í™•ì¸.)
    
    try:
        state_after_planner = planner_node(state_after_trend)
        content_brief = state_after_planner.get("content_brief")
        
        logger.info("âœ… ê¸°íšì•ˆ(Content Brief) ìƒì„± ì™„ë£Œ")
        logger.info(json.dumps(content_brief, indent=2, ensure_ascii=False))
        
        # ê¸°íšì•ˆ ê²€ì¦: Trendê°€ ë°˜ì˜ë˜ì—ˆë‚˜?
        # ì‚¬ëŒì´ ì§ì ‘ ëˆˆìœ¼ë¡œ ë´ì•¼ ì•Œ ìˆ˜ ìˆìŒ (Contextì— ë“¤ì–´ê°”ëŠ”ì§€ ë¡œê·¸ë¡œ í™•ì¸ ë“±)

    except Exception as e:
        logger.error(f"âŒ Planner ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        return

    print("\n" + "="*50 + "\n")

    # 3. News Research ì‹¤í–‰ (ê¸°íšì•ˆ ê¸°ë°˜ íŒ©íŠ¸ ìˆ˜ì§‘)
    logger.info("ğŸ¬ [Step 3] News Research: íŒ©íŠ¸ & í•µì‹¬ ë¬¸ë‹¨ ìˆ˜ì§‘ ì‹œì‘")
    # News ResearchëŠ” content_brief['researchPlan']ì„ ì‚¬ìš©í•¨
    
    try:
        # ì‹œê°„ ì ˆì•½ì„ ìœ„í•´ ì¿¼ë¦¬ 1ê°œë§Œ ë‚¨ê¸°ê³  í…ŒìŠ¤íŠ¸ (ì‹¤ì œë¡œëŠ” ë‹¤ ëŒë¦¼)
        if content_brief and "researchPlan" in content_brief:
             original_queries = content_brief["researchPlan"].get("newsQuery", [])
             content_brief["researchPlan"]["newsQuery"] = original_queries[:1] # í…ŒìŠ¤íŠ¸ìš© 1ê°œë§Œ
             logger.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì²« ë²ˆì§¸ ì¿¼ë¦¬ '{original_queries[0]}'ë§Œ ì‹¤í–‰í•©ë‹ˆë‹¤.")

        state_after_news = news_research_node(state_after_planner)
        news_data = state_after_news.get("news_data", {})
        articles = news_data.get("articles", [])
        
        logger.info(f"âœ… ìˆ˜ì§‘ëœ ê¸°ì‚¬ ìˆ˜: {len(articles)}ê°œ")
        for i, art in enumerate(articles):
            logger.info(f"ğŸ“„ Article #{i+1}: {art['title']}")
            logger.info(f"   - í•µì‹¬ ë¬¸ë‹¨(Summary) ê¸¸ì´: {len(art.get('summary', ''))}ì")
            logger.info(f"   - ì°¨íŠ¸: {len(art.get('charts', []))}ê°œ / ì´ë¯¸ì§€: {len(art.get('images', []))}ê°œ")
            if art.get("summary"):
                logger.info(f"   ğŸ“ Summary Preview: {art['summary'][:100]}...")

    except Exception as e:
        logger.error(f"âŒ News Research ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        return

    print("\n" + "="*50 + "\n")
    logger.info("ğŸ‰ í†µí•© íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

if __name__ == "__main__":
    test_integration_pipeline()
